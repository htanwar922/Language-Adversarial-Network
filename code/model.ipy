#!/usr/bin/env ipython

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models

class DAN_Fetaure_Extractor(tf.nn.Module):
	def __init__(self, vocab, num_layers, hidden_size, pooling='avg', dropout=0, batch_norm=False):
		super(DAN_Feature_Extractor, self).__init__()

		if(pooling == 'sum' or pooling == 'add'): self.pool = layers.Add(self.word_emb)
		else: self.pool = layers.Average(self.word_emb)

		assert num_layers >= 0, 'Invalid layer numbers'

		self.fcnet = models.Sequential()
		for i in range(num_layers):
            if dropout > 0:
                self.fcnet.add(layers.Dropout(rate=dropout))
            if i == 0:
                self.fcnet.add(layers.Linear(vocab.emb_size, hidden_size))
            else:
                self.fcnet.add_module('f-linear-{}'.format(i), nn.Linear(hidden_size, hidden_size))
            if batch_norm:
                self.fcnet.add_module('f-bn-{}'.format(i), nn.BatchNorm1d(hidden_size))
            self.fcnet.add_module('f-relu-{}'.format(i), nn.ReLU())
